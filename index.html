<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>SC Screen Recorder</title>
  <link rel='icon' type='image/png' href='/favicon.png'>
  <link href="index.css" rel="stylesheet" />
</head>

<body>

  <!-- This is the displayed page -->
  <div id="my-canvas-container">
    <canvas id="my-canvas" data-scrawl-canvas data-is-responsive="true"></canvas>
  </div>

  <div id="control-buttons">
    <a href="https://github.com/KaliedaRik/sc-screen-recorder" target="_BLANK">Instructions</a>
    <button id="target-button">No Javascript running</button>
    <button id="video-button" disabled>Cannot record video</button>
    <button id="button-3" disabled>Download</button>
  </div>

  <!-- 
    This is the mediapipe code, for getting the user's face into the screen capture video

    mediapipe-camera-utils.js - taken from https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js on 3 May 2025. Copyright The Closure Library Authors. SPDX-License-Identifier: Apache-2.0

    mediapipe-selfie-segmentation.js - taken from https://cdn.jsdelivr.net/npm/@mediapipe/selfie_segmentation/selfie_segmentation.js on 3 May 2025. Copyright The Closure Library Authors. SPDX-License-Identifier: Apache-2.0
  -->
  <script src="js/mediapipe-camera-utils.js"></script>
  <script src="js/mediapipe-selfie-segmentation.js"></script>

  <script type="module">

    // ------------------------------------------------------------------------
    // Scrawl-canvas boilerplate
    // ------------------------------------------------------------------------
    import * as scrawl from './js/scrawl.js';
    const name = (n) => `canvas-${n}`;
    const canvas = scrawl.findCanvas('my-canvas');


    // ------------------------------------------------------------------------
    // Scrawl-canvas animation
    // ------------------------------------------------------------------------
    scrawl.makeRender({

      name: name('render'),
      target: canvas,
    });


    // ------------------------------------------------------------------------
    // Talking head - with the help of a Google MediaPipe solution
    // - https://ai.google.dev/edge/mediapipe/solutions/guide
    // ------------------------------------------------------------------------

    // Talking head can go in its own Cell
    const talkingHeadAsset = canvas.buildCell({

      name: name('talking-head-asset'),
      dimensions: ['25%', '25%'],
      shown: false,
    });

    // Displaying the Cell in the canvas
    scrawl.makePicture({

      name: name('talking-head'),
      asset: talkingHeadAsset,
      order: 1,

      dimensions: ['35%', '35%'],
      copyDimensions: ['100%', '100%'],

      start: ['right', 'bottom'],
      handle: ['right', 'bottom'],
    });

    // Some convenience handles for the media stream asset
    let myMediaStream, mySegmentationModel, myBackground, myOutline;

    // Blur filter, to make the talking head meld with the background
    scrawl.makeFilter({

      name: name('body-blur'),
      method: 'gaussianBlur',
      radius: 10,
    });

    // MediaPipe outputs its results to a WebGL canvas element - SC can use that as an asset source
    // But because we want to manipulate that data we can route it through an SC raw asset wrapper
    const myModelOutputWrapper = scrawl.makeRawAsset({

      name: name('mediapipe-model-interpreter'),

      userAttributes: [
        {

          key: 'mask',
          defaultValue: [],
          setter: function (item) {

            item = (item.segmentationMask) ? item.segmentationMask : false;

            if (item) {

              this.canvasWidth = item.width;
              this.canvasHeight = item.height;
              this.mask = item;
              this.dirtyData = true;
            }
          },

        },{

          key: 'canvasWidth',
          defaultValue: 0,
          setter: () => {},

        },{

          key: 'canvasHeight',
          defaultValue: 0,
          setter: () => {},
        }
      ],

      updateSource: function (assetWrapper) {

        const { element, engine, canvasWidth, canvasHeight, mask } = assetWrapper;

        if (canvasWidth && canvasHeight && mask) {

          element.width = canvasWidth;
          element.height = canvasHeight;

          engine.drawImage(mask, 0, 0, canvasWidth, canvasHeight);
        }
      },
    });

    // The forever loop function captures the MediaPipe model's output and passes it on to our raw asset for processing
    const updateModelOutputWrapper = function (mask) {

      myModelOutputWrapper.set({ mask });

      if (!myOutline) {

        myOutline = scrawl.makePicture({

          name: name('mediapipe-results-outline'),
          group: talkingHeadAsset,
          asset: myModelOutputWrapper,
          dimensions: ['100%', '100%'],
          copyDimensions: ['100%', '100%'],
          filters: [name('body-blur')],
        });
      }
    };

    // Capture the user's device media stream
    scrawl.importMediaStream({

      name: name('device-camera'),
      audio: false,

    }).then(mycamera => {

      myMediaStream = mycamera;

      // Firefox bugfix
      myMediaStream.source.width = "1280";
      myMediaStream.source.height = "720";

      scrawl.makePicture({

        name: name('body'),
        group: talkingHeadAsset,
        asset: mycamera.name,
        order: 1,

        dimensions: ['100%', '100%'],
        copyDimensions: ['100%', '100%'],

        globalCompositeOperation: 'source-in',
      });

      // Start the MediaPipe model
      // The SelfieSegmentation object/class comes from the mediapipe-selfie-segmentation.js code
      mySegmentationModel = new SelfieSegmentation({

        // Have to go outside for this because I don't understand what the model wants
        locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/selfie_segmentation/${file}`,
      });

      mySegmentationModel.setOptions({ modelSelection: 1 });
      mySegmentationModel.onResults(updateModelOutputWrapper);

      // The Camera object/class comes from the mediapipe-camera-utils.js code
      const mediaPipeCamera = new Camera(myMediaStream.source, {

        onFrame: async () => {

          await mySegmentationModel.send({image: myMediaStream.source});
        },

        width: 1280,
        height: 720,
      });

      mediaPipeCamera.start();

    }).catch(err => console.log(err.message));


    // ------------------------------------------------------------------------
    // Control buttons management
    // ------------------------------------------------------------------------
    const dom = scrawl.initializeDomInputs([
      ['button', 'target-button', 'Target'],
      ['button', 'video-button', 'Record'],
    ]);

    const targetButton = dom['target-button'],
      videoButton = dom['video-button'];


    // ------------------------------------------------------------------------
    // Screen capture button management
    // ------------------------------------------------------------------------
    let targetPicure;

    const requestScreenCapture = () => {

      scrawl.importScreenCapture({

        name: name('my-screen-capture'),
        audio: { suppressLocalAudioPlayback: true },
      })
      .then(mycamera => {

        targetButton.setAttribute('disabled', '');
        videoButton.removeAttribute('disabled')

        targetPicure = scrawl.makePicture({

          name: name('background'),
          asset: mycamera.name,

          dimensions: ['100%', '100%'],
          copyDimensions: ['100%', '100%'],
        });
      })
      .catch(err => {

        targetButton.removeAttribute('disabled');
        videoButton.setAttribute('disabled', '');
      });
    };

    scrawl.addNativeListener('click', requestScreenCapture, targetButton);


    // ------------------------------------------------------------------------
    // Video recording and download functionality
    // ------------------------------------------------------------------------
    let isRecordingVideo = false,
      recorder, recordedChunks;

    videoButton.addEventListener("click", () => {

      isRecordingVideo = !isRecordingVideo;

      if (isRecordingVideo) {

        videoButton.textContent = "Stop";

        const stream = canvas.domElement.captureStream(25);

        recorder = new MediaRecorder(stream, {
          mimeType: "video/webm;codecs=vp8"
        });

        recordedChunks = [];

        recorder.ondataavailable = (e) => {

          if (e.data.size > 0) recordedChunks.push(e.data);
        };

          recorder.start();
        }
      else {

        videoButton.textContent = "Record";

        recorder.stop();

        setTimeout(() => {

          const blob = new Blob(recordedChunks, { type: "video/webm" });

          const url = URL.createObjectURL(blob);
          const a = document.createElement("a");

          a.href = url;
          a.download = `SC-screen-recording_${Date().slice(4, 24)}.webm`;
          a.click();

          URL.revokeObjectURL(url);
        }, 0);
      }
    });


    // ------------------------------------------------------------------------
    // Development and troubleshooting
    // ------------------------------------------------------------------------
    console.log(scrawl.library);

  </script>
</body>
</html>
